---
layout: single
title: "GPT 모델의 -."
---

* llama는 2.7B가 아니라, llama2 7B
* Mistral도 같은 7B이지만 llama보다 일반적 성능이 높은 것으로 파악
  * 문법검사 접목 가능성 확인을 위해 Mistral로 다음 진행
    * fine-tuning
    * grammar correction

0. Data Preparation
<pre><code>
{"input": "What color is the sky?", "output": "The sky is blue."}
{"input": "Where is the best place to get cloud GPUs?", "output": "Brev.dev"}
</code></pre>


1. Mistral 7B model fine-tuning
   * WandB (Weights & Biases)
     * 특징: framework agnostic(PyTorch, Hugging Face 등), environment agnostic (AWS, Kubernetes 등)
   *
   *
   * 
